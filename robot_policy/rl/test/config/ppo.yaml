agent:
    env_name:               Pendulum-v0
    env_config:             {render: True, action_wrapper: False, make: True}
    seed:                   123
    use_gpu:                True
    render_every_n_rollout: 100
    play_every_n_rollout:   20

    # train
    rollout_steps:          2000
    max_steps:              400000
    batch_size:             128
    train_mini_epochs:      10
    max_grad_norm:          0.8

    # on policy train
    gamma:                  0.99
    gae_lambda:             0.97
    ent_coef:               0.0
    val_coef:               0.5
    use_sde:                False
    sde_sample_freq:        -1
    num_env:                1

    # ppo train
    clip_range:             0.2
    # clip_range_vf:          None
    # target_kl:              0.01

    policy_type:            ActorCriticSimplePolicy

policy:
    network_type:           mlp
    network_config:
        net_struct:         {shared: [], policy: [ 64, 64 ], value: [ 64, 64 ]}
        activation_fn:      ReLU
        log_std_init:       0.0
    optimizer_type:         Adam
    optimizer_config:
        lr:                 0.0003
    scheduler_type:         ReduceLROnPlateau
    scheduler_config:
        patience:           10
        min_lr:             1e-6
        factor:             0.5
        verbose:            False
    squash_output:          True



